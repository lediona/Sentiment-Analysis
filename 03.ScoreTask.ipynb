{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreTAsk\n",
    "\n",
    "\n",
    " * ` * `ScoreTask`: Uses the scored model to compute the sentiment for each city.\n",
    "    * Use the trained model to predict the probability/score for each city the\n",
    "      negative, neutral and positive sentiment.\n",
    "    * Output a sorted list of cities by the predicted positive sentiment score to the output file.\n",
    "\n",
    "\"\"\" Uses the scored model to compute the sentiment for each city.\n",
    "\n",
    "        Output file should be a four column CSV with columns:\n",
    "        - city name\n",
    "        - negative probability\n",
    "        - neutral probability\n",
    "        - positive probability\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def read_in_dataset(dset, verbose=False):\n",
      "    \n",
      "    \"\"\"Read in one of the datasets (train or properties)\n",
      "        \n",
      "        Keyword arguments:\n",
      "        dset -- a string\n",
      "        verbose -- whether or not to print info about the dataset\n",
      "        \n",
      "        Returns:\n",
      "        a pandas dataframe\n",
      "        \"\"\"\n",
      "    \n",
      "    df =  pd.read_csv('{0}.csv'.format(dset), encoding = \"ISO-8859-1\")\n",
      "    \n",
      "    if verbose:\n",
      "        print('\\n{0:*^80}'.format(' Reading in the {0} dataset '.format(dset)))\n",
      "        print(\"\\nit has {0} rows and {1} columns\".format(*df.shape))\n",
      "        print('\\n{0:*^80}\\n'.format(' It has the following columns '))\n",
      "        print(df.columns)\n",
      "        print('\\n{0:*^80}\\n'.format(' The first 5 rows look like this '))\n",
      "        print(df.head())\n",
      "    \n",
      "    return df\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules.helpers import read_in_dataset\n",
    "import inspect\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(inspect.getsource(read_in_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************* Reading in the training_data dataset *********************\n",
      "\n",
      "it has 855 rows and 22 columns\n",
      "\n",
      "************************* It has the following columns *************************\n",
      "\n",
      "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'airline_sentiment',\n",
      "       'airline_sentiment:confidence', 'negativereason',\n",
      "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
      "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone',\n",
      "       'closest_cities', 'sentiment'],\n",
      "      dtype='object')\n",
      "\n",
      "*********************** The first 5 rows look like this ************************\n",
      "\n",
      "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
      "0  681448197    False   finalized                   3      2/25/15 2:26   \n",
      "1  681448213    False   finalized                   3      2/25/15 9:04   \n",
      "2  681448214    False   finalized                   3      2/25/15 9:14   \n",
      "3  681448223    False   finalized                   3      2/25/15 1:57   \n",
      "4  681448228    False   finalized                   3      2/25/15 1:01   \n",
      "\n",
      "  airline_sentiment  airline_sentiment:confidence          negativereason  \\\n",
      "0          positive                         1.000                     NaN   \n",
      "1          negative                         1.000              Bad Flight   \n",
      "2           neutral                         0.615                     NaN   \n",
      "3          negative                         1.000  Customer Service Issue   \n",
      "4          positive                         1.000                     NaN   \n",
      "\n",
      "   negativereason:confidence         airline  ... negativereason_gold  \\\n",
      "0                        NaN  Virgin America  ...                 NaN   \n",
      "1                        1.0  Virgin America  ...                 NaN   \n",
      "2                        0.0  Virgin America  ...                 NaN   \n",
      "3                        1.0  Virgin America  ...                 NaN   \n",
      "4                        NaN  Virgin America  ...                 NaN   \n",
      "\n",
      "  retweet_count                                               text  \\\n",
      "0             0  @VirginAmerica I love this graphic. http://t.c...   \n",
      "1             0  @VirginAmerica amazing to me that we can't get...   \n",
      "2             0  @VirginAmerica LAX to EWR - Middle seat on a r...   \n",
      "3             0  @VirginAmerica help, left expensive headphones...   \n",
      "4             0  @VirginAmerica this is great news!  America co...   \n",
      "\n",
      "                    tweet_coord  tweet_created      tweet_id  \\\n",
      "0   [40.74804263, -73.99295302]   2/24/15 8:49  5.702640e+17   \n",
      "1     [42.361016, -71.02000488]   2/24/15 5:05  5.702080e+17   \n",
      "2   [33.94540417, -118.4062472]  2/23/15 23:34  5.701250e+17   \n",
      "3  [33.94209449, -118.40410103]  2/23/15 21:10  5.700880e+17   \n",
      "4     [33.2145038, -96.9321504]  2/23/15 20:24  5.700770e+17   \n",
      "\n",
      "                  tweet_location               user_timezone closest_cities  \\\n",
      "0                            NaN                         NaN  New York City   \n",
      "1  San Mateo, CA & Las Vegas, NV                         NaN        Chelsea   \n",
      "2                       Brooklyn      Atlantic Time (Canada)     El Segundo   \n",
      "3                  Washington DC                       Quito     El Segundo   \n",
      "4                          Texas  Central Time (US & Canada)         Frisco   \n",
      "\n",
      "  sentiment  \n",
      "0       2.0  \n",
      "1       0.0  \n",
      "2       1.0  \n",
      "3       0.0  \n",
      "4       2.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "training_data_df= read_in_dataset('training_data', verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine X and Y and the training set\n",
    "-  The \"y\" variable will be the multi-class sentiment (0, 1, 2 for negative, neutral and positive respectively).\n",
    "- * The \"X\" variables will be the closest city to the \"tweet_coord\" using Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data_df.closest_cities\n",
    "y = training_data_df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 253)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "encoder = LabelBinarizer()\n",
    "X_train_lb = encoder.fit_transform(X_train)\n",
    "X_train_lb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lb = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Probabilities with  Softmax Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model.pkl'\n",
    "softmax_clf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = softmax_clf.predict_proba(X_test_lb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the cities name with the labels of sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>newcol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>[0.7766233837170984, 0.15829126945162666, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bowie</td>\n",
       "      <td>[0.6582538859242353, 0.1635033921677491, 0.178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Franklin Park</td>\n",
       "      <td>[0.7046701569351638, 0.09846966682839016, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dubai</td>\n",
       "      <td>[0.471176832517254, 0.35672426312421485, 0.172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>[0.7856497243006918, 0.10336717367645293, 0.11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_name                                             newcol\n",
       "0         Newark  [0.7766233837170984, 0.15829126945162666, 0.06...\n",
       "1          Bowie  [0.6582538859242353, 0.1635033921677491, 0.178...\n",
       "2  Franklin Park  [0.7046701569351638, 0.09846966682839016, 0.19...\n",
       "3          Dubai  [0.471176832517254, 0.35672426312421485, 0.172...\n",
       "4    Miami Beach  [0.7856497243006918, 0.10336717367645293, 0.11..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_name = X_test.to_list()\n",
    "new_col = probabilities.tolist()\n",
    "data_tuples = list(zip(city_name,new_col))\n",
    "df = pd.DataFrame(data_tuples, columns=['city_name','newcol'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.7766233837170984, 0.15829126945162666, 0.06...\n",
       "1    [0.6582538859242353, 0.1635033921677491, 0.178...\n",
       "2    [0.7046701569351638, 0.09846966682839016, 0.19...\n",
       "3    [0.471176832517254, 0.35672426312421485, 0.172...\n",
       "4    [0.7856497243006918, 0.10336717367645293, 0.11...\n",
       "Name: newcol, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['newcol' ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>negative probability</th>\n",
       "      <th>neutral probability</th>\n",
       "      <th>positive sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>0.776623</td>\n",
       "      <td>0.158291</td>\n",
       "      <td>0.065085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bowie</td>\n",
       "      <td>0.658254</td>\n",
       "      <td>0.163503</td>\n",
       "      <td>0.178243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Franklin Park</td>\n",
       "      <td>0.704670</td>\n",
       "      <td>0.098470</td>\n",
       "      <td>0.196860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dubai</td>\n",
       "      <td>0.471177</td>\n",
       "      <td>0.356724</td>\n",
       "      <td>0.172099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>0.785650</td>\n",
       "      <td>0.103367</td>\n",
       "      <td>0.110983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_name  negative probability  neutral probability  \\\n",
       "0         Newark              0.776623             0.158291   \n",
       "1          Bowie              0.658254             0.163503   \n",
       "2  Franklin Park              0.704670             0.098470   \n",
       "3          Dubai              0.471177             0.356724   \n",
       "4    Miami Beach              0.785650             0.103367   \n",
       "\n",
       "   positive sentiment  \n",
       "0            0.065085  \n",
       "1            0.178243  \n",
       "2            0.196860  \n",
       "3            0.172099  \n",
       "4            0.110983  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['negative probability','neutral probability', 'positive sentiment']] = pd.DataFrame(df.newcol.values.tolist(), index= df.index)\n",
    "df.drop(columns='newcol', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scores.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
