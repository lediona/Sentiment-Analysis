{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Model_Task_Model_Tuning\n",
    "\n",
    "\n",
    " * ` Trains a classifier to predict negative, neutral, positive based only on the input city.\n",
    "    * Train a classifier that uses closest cities as features.\n",
    "    * Dump the fitted model to the output file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def read_in_dataset(dset, verbose=False):\n",
      "    \n",
      "    \"\"\"Read in one of the datasets (train or properties)\n",
      "        \n",
      "        Keyword arguments:\n",
      "        dset -- a string\n",
      "        verbose -- whether or not to print info about the dataset\n",
      "        \n",
      "        Returns:\n",
      "        a pandas dataframe\n",
      "        \"\"\"\n",
      "    \n",
      "    df =  pd.read_csv('{0}.csv'.format(dset), encoding = \"ISO-8859-1\")\n",
      "    \n",
      "    if verbose:\n",
      "        print('\\n{0:*^80}'.format(' Reading in the {0} dataset '.format(dset)))\n",
      "        print(\"\\nit has {0} rows and {1} columns\".format(*df.shape))\n",
      "        print('\\n{0:*^80}\\n'.format(' It has the following columns '))\n",
      "        print(df.columns)\n",
      "        print('\\n{0:*^80}\\n'.format(' The first 5 rows look like this '))\n",
      "        print(df.head())\n",
      "    \n",
      "    return df\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from modules.helpers import read_in_dataset\n",
    "import inspect\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(inspect.getsource(read_in_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************* Reading in the training_data dataset *********************\n",
      "\n",
      "it has 855 rows and 22 columns\n",
      "\n",
      "************************* It has the following columns *************************\n",
      "\n",
      "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'airline_sentiment',\n",
      "       'airline_sentiment:confidence', 'negativereason',\n",
      "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
      "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone',\n",
      "       'closest_cities', 'sentiment'],\n",
      "      dtype='object')\n",
      "\n",
      "*********************** The first 5 rows look like this ************************\n",
      "\n",
      "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
      "0  681448197    False   finalized                   3      2/25/15 2:26   \n",
      "1  681448213    False   finalized                   3      2/25/15 9:04   \n",
      "2  681448214    False   finalized                   3      2/25/15 9:14   \n",
      "3  681448223    False   finalized                   3      2/25/15 1:57   \n",
      "4  681448228    False   finalized                   3      2/25/15 1:01   \n",
      "\n",
      "  airline_sentiment  airline_sentiment:confidence          negativereason  \\\n",
      "0          positive                         1.000                     NaN   \n",
      "1          negative                         1.000              Bad Flight   \n",
      "2           neutral                         0.615                     NaN   \n",
      "3          negative                         1.000  Customer Service Issue   \n",
      "4          positive                         1.000                     NaN   \n",
      "\n",
      "   negativereason:confidence         airline  ... negativereason_gold  \\\n",
      "0                        NaN  Virgin America  ...                 NaN   \n",
      "1                        1.0  Virgin America  ...                 NaN   \n",
      "2                        0.0  Virgin America  ...                 NaN   \n",
      "3                        1.0  Virgin America  ...                 NaN   \n",
      "4                        NaN  Virgin America  ...                 NaN   \n",
      "\n",
      "  retweet_count                                               text  \\\n",
      "0             0  @VirginAmerica I love this graphic. http://t.c...   \n",
      "1             0  @VirginAmerica amazing to me that we can't get...   \n",
      "2             0  @VirginAmerica LAX to EWR - Middle seat on a r...   \n",
      "3             0  @VirginAmerica help, left expensive headphones...   \n",
      "4             0  @VirginAmerica this is great news!  America co...   \n",
      "\n",
      "                    tweet_coord  tweet_created      tweet_id  \\\n",
      "0   [40.74804263, -73.99295302]   2/24/15 8:49  5.702640e+17   \n",
      "1     [42.361016, -71.02000488]   2/24/15 5:05  5.702080e+17   \n",
      "2   [33.94540417, -118.4062472]  2/23/15 23:34  5.701250e+17   \n",
      "3  [33.94209449, -118.40410103]  2/23/15 21:10  5.700880e+17   \n",
      "4     [33.2145038, -96.9321504]  2/23/15 20:24  5.700770e+17   \n",
      "\n",
      "                  tweet_location               user_timezone closest_cities  \\\n",
      "0                            NaN                         NaN  New York City   \n",
      "1  San Mateo, CA & Las Vegas, NV                         NaN        Chelsea   \n",
      "2                       Brooklyn      Atlantic Time (Canada)     El Segundo   \n",
      "3                  Washington DC                       Quito     El Segundo   \n",
      "4                          Texas  Central Time (US & Canada)         Frisco   \n",
      "\n",
      "  sentiment  \n",
      "0       2.0  \n",
      "1       0.0  \n",
      "2       1.0  \n",
      "3       0.0  \n",
      "4       2.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "training_data_df= read_in_dataset('training_data', verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine X and Y and the training set\n",
    "-  The \"y\" variable will be the multi-class sentiment (0, 1, 2 for negative, neutral and positive respectively).\n",
    "- * The \"X\" variables will be the closest city to the \"tweet_coord\" using Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data_df.closest_cities\n",
    "y = training_data_df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684,)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684,)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualize the classes and their ditribution at the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13347f090>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.hist()  # we have an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    467\n",
       "2.0    115\n",
       "1.0    102\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() # 467 negative sentiments, 115 neutral and 102 positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling categorical features\n",
    "- one-hot encoding the names of the closest cities\n",
    "- Another way is using LabelBinarizer to apply both transformation: from text to integer categories, then from integer categories  to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique cities do we have\n",
    "len(X_train.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one hot encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(np.array(X_train).reshape(-1,1))\n",
    "X_train_ohe_dense = X_train_ohe.toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 253)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe_dense.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 253)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelBinarizer()\n",
    "X_train_lb = encoder.fit_transform(X_train)\n",
    "X_train_lb.shape # dense matrix with shape (684, 253)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Success Metrics for Computing the Scores\n",
    "- this is a multiclass classification problem (0,1,2) classes\n",
    "- the classes are imbalanced therefore accuracy is not approapriate to be used as a metric in this problem\n",
    "- We will use various classification algorithms  and will evaluate them\n",
    "- Will use recall-macro that is appropriate metric for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent  Classifier- linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train_lb, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 253)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lb = encoder.transform(X_test)\n",
    "X_test_lb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.,\n",
       "       0., 0., 2., 0., 0., 2., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 2.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 2., 2., 0., 2., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sgd_clf.predict(X_test_lb)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix- Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[433,  18,  16],\n",
       "       [ 90,   7,   5],\n",
       "       [102,  10,   3]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train_lb, y_train, cv=3)\n",
    "conf_mx = confusion_matrix (y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32088989, 0.36105819, 0.34562735])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train_lb, y_train, cv=3, scoring = 'recall_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the performance \n",
    "- oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE('minority')\n",
    "X_sm, Y_sm = smote.fit_sample(X_train_lb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_sm, Y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42735043, 0.51518219, 0.5401245 ])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_sm, Y_sm, cv=3, scoring = 'recall_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for multiclass classification- OneVsResClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0,\n",
       "                                                               class_weight=None,\n",
       "                                                               dual=True,\n",
       "                                                               fit_intercept=True,\n",
       "                                                               intercept_scaling=1,\n",
       "                                                               loss='squared_hinge',\n",
       "                                                               max_iter=1000,\n",
       "                                                               multi_class='ovr',\n",
       "                                                               penalty='l2',\n",
       "                                                               random_state=None,\n",
       "                                                               tol=0.0001,\n",
       "                                                               verbose=0),\n",
       "                                           n_jobs=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'estimator__C': [0.5, 1.0, 1.5],\n",
       "                         'estimator__tol': [0.001, 0.0001, 1e-05]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_weighted', verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_SVM = OneVsRestClassifier(LinearSVC())\n",
    "params = {\n",
    "      'estimator__C': [0.5, 1.0, 1.5],\n",
    "      'estimator__tol': [1e-3, 1e-4, 1e-5],\n",
    "      }\n",
    "grid = GridSearchCV(clf_SVM, params, cv=5, scoring='f1_weighted')\n",
    "grid.fit(X_sm, Y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid = grid.predict(X_test_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "def scores(y_test, y_pred):\n",
    "    \n",
    "    precision, recall, fscore, support = score(y_test, y_pred)\n",
    "\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('fscore: {}'.format(fscore))\n",
    "    print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.71       0.27692308 0.5       ]\n",
      "recall: [0.66981132 0.6        0.08571429]\n",
      "fscore: [0.68932039 0.37894737 0.14634146]\n",
      "support: [106  30  35]\n"
     ]
    }
   ],
   "source": [
    "scores(y_test, y_pred_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for multiclass classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=20, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid=False, n_jobs=None,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'], 'max_depth': [3, 15],\n",
       "                         'max_features': [1, 3, 10],\n",
       "                         'min_samples_split': [2, 3, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(n_estimators=20)\n",
    "param_grid = {\"max_depth\": [3, 15],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search_forest = GridSearchCV(forest_clf, param_grid=param_grid, cv=5, iid=False)\n",
    "grid_search_forest.fit(X_sm, Y_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.73529412 0.23300971 0.        ]\n",
      "recall: [0.47169811 0.8        0.        ]\n",
      "fscore: [0.57471264 0.36090226 0.        ]\n",
      "support: [106  30  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred_grid_forest = grid_search_forest.predict(X_test_lb)\n",
    "scores(y_test, y_pred_grid_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "- Create model container and add models to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model container\n",
    "from modules.model_container import ept\n",
    "models = ModelContainer()\n",
    "\n",
    "#create models -- hyperparameter tuning already done by hand for each model\n",
    "models.add_model(SGDClassifier())\n",
    "models.add_model(GridSearchCV(forest_clf, param_grid=param_grid, cv=5, iid=False))\n",
    "models.add_model(GridSearchCV(clf_SVM, params, cv=5, scoring='f1_weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validate models, then select, fit, and score test data with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True,\n",
      "                                        fit_intercept=True, intercept_scaling=1,\n",
      "                                        loss='squared_hinge', max_iter=1000,\n",
      "                                        multi_class='ovr', penalty='l2',\n",
      "                                        random_state=None, tol=0.0001,\n",
      "                                        verbose=0),\n",
      "                    n_jobs=None)\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators=20, n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid=False, n_jobs=None,\n",
      "             param_grid={'bootstrap': [True, False],\n",
      "                         'criterion': ['gini', 'entropy'], 'max_depth': [3, 15],\n",
      "                         'max_features': [1, 3, 10],\n",
      "                         'min_samples_split': [2, 3, 10]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True,\n",
      "                                        fit_intercept=True, intercept_scaling=1,\n",
      "                                        loss='squared_hinge', max_iter=1000,\n",
      "                                        multi_class='ovr', penalty='l2',\n",
      "                                        random_state=None, tol=0.0001,\n",
      "                                        verbose=0),\n",
      "                    n_jobs=None)\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators=20, n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid=False, n_jobs=None,\n",
      "             param_grid={'bootstrap': [True, False],\n",
      "                         'criterion': ['gini', 'entropy'], 'max_depth': [3, 15],\n",
      "                         'max_features': [1, 3, 10],\n",
      "                         'min_samples_split': [2, 3, 10]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0,\n",
      "                                                               class_weight=None,\n",
      "                                                               dual=True,\n",
      "                                                               fit_intercept=True,\n",
      "                                                               intercept_scaling=1,\n",
      "                                                               loss='squared_hinge',\n",
      "                                                               max_iter=1000,\n",
      "                                                               multi_class='ovr',\n",
      "                                                               penalty='l2',\n",
      "                                                               random_state=None,\n",
      "                                                               tol=0.0001,\n",
      "                                                               verbose=0),\n",
      "                                           n_jobs=None),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'estimator__C': [0.5, 1.0, 1.5],\n",
      "                         'estimator__tol': [0.001, 0.0001, 1e-05]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring='f1_weighted', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "num_procs = 4\n",
    "models.cross_validate(training_data_df, k=2, num_procs=num_procs)\n",
    "models.select_best_model()\n",
    "models.best_model_fit(X_sm, Y_sm)\n",
    "models.best_model_predict(X_test_lb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summaries:\n",
      "\n",
      "\n",
      " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 0.5014816665580396\n",
      "\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=15, max_features=3, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) - MSE: 0.459001259430444\n",
      "\n",
      " OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True,\n",
      "                                        fit_intercept=True, intercept_scaling=1,\n",
      "                                        loss='squared_hinge', max_iter=1000,\n",
      "                                        multi_class='ovr', penalty='l2',\n",
      "                                        random_state=None, tol=0.0001,\n",
      "                                        verbose=0),\n",
      "                    n_jobs=None) - MSE: 0.49628627464478003\n",
      "\n",
      " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 0.4998750400361206\n",
      "\n",
      " GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators=20, n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid=False, n_jobs=None,\n",
      "             param_grid={'bootstrap': [True, False],\n",
      "                         'criterion': ['gini', 'entropy'], 'max_depth': [3, 15],\n",
      "                         'max_features': [1, 3, 10],\n",
      "                         'min_samples_split': [2, 3, 10]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0) - MSE: 0.44969003338102054\n",
      "\n",
      " OneVsRestClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=True,\n",
      "                                        fit_intercept=True, intercept_scaling=1,\n",
      "                                        loss='squared_hinge', max_iter=1000,\n",
      "                                        multi_class='ovr', penalty='l2',\n",
      "                                        random_state=None, tol=0.0001,\n",
      "                                        verbose=0),\n",
      "                    n_jobs=None) - MSE: 0.49628627464478003\n",
      "\n",
      " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) - MSE: 0.5099724087245799\n",
      "\n",
      " GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators=20, n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid=False, n_jobs=None,\n",
      "             param_grid={'bootstrap': [True, False],\n",
      "                         'criterion': ['gini', 'entropy'], 'max_depth': [3, 15],\n",
      "                         'max_features': [1, 3, 10],\n",
      "                         'min_samples_split': [2, 3, 10]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0) - MSE: 0.46968807698421433\n",
      "\n",
      " GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=OneVsRestClassifier(estimator=LinearSVC(C=1.0,\n",
      "                                                               class_weight=None,\n",
      "                                                               dual=True,\n",
      "                                                               fit_intercept=True,\n",
      "                                                               intercept_scaling=1,\n",
      "                                                               loss='squared_hinge',\n",
      "                                                               max_iter=1000,\n",
      "                                                               multi_class='ovr',\n",
      "                                                               penalty='l2',\n",
      "                                                               random_state=None,\n",
      "                                                               tol=0.0001,\n",
      "                                                               verbose=0),\n",
      "                                           n_jobs=None),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'estimator__C': [0.5, 1.0, 1.5],\n",
      "                         'estimator__tol': [0.001, 0.0001, 1e-05]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring='f1_weighted', verbose=0) - MSE: 0.49628627464478003\n",
      "\n",
      "Best Model:\n",
      " SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "RECALL of Best Model\n",
      " 0.5099724087245799\n"
     ]
    }
   ],
   "source": [
    "models.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  -Conclusion: The best model based on recall_macro is SGD classifier 0.5099\n",
    "  - however based on the requirement the at the Luigi framework it is asked that the score.csv file should be compled with the probabilites of the that classifier assigns to the classes\n",
    "  - therefore I decided to use the Logistic Regression. Logistic regression is used for binary classifier, due tot the fact that the we have multiclass classification problem the right algorithm to use it Softmax Regression\n",
    "  or Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Probabilities with  Softmax Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "softmax_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "softmax_clf.fit(X_sm, Y_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = softmax_clf.predict_proba(X_test_lb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49901203933461996"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_macro = cross_val_score(softmax_clf, X_sm, Y_sm, cv=3, n_jobs=4, scoring='recall_macro')\n",
    "mean_recall_macro = np.mean(recall_macro)\n",
    "mean_recall_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model.pkl'\n",
    "pickle.dump(lg_clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
