{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training_data_task_Data_prep\n",
    "\n",
    " * `TrainingDataTask`: Extracts features/outcome variable in preparation for training a model.\n",
    "    * This prepares the cleaned data into the exact form that is able to be fit by the model.\n",
    "    * The \"y\" variable will be the multi-class sentiment (0, 1, 2 for negative, neutral and positive respectively).\n",
    "    * The \"X\" variables will be the closest city to the \"tweet_coord\" using Euclidean distance.\n",
    "    * You should use the `cities.csv` file to find the closest city.\n",
    "    * You probably will need to one-hot encode the city names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def read_in_dataset(dset, verbose=False):\n",
      "    \n",
      "    \"\"\"Read in one of the datasets (train or properties)\n",
      "        \n",
      "        Keyword arguments:\n",
      "        dset -- a string\n",
      "        verbose -- whether or not to print info about the dataset\n",
      "        \n",
      "        Returns:\n",
      "        a pandas dataframe\n",
      "        \"\"\"\n",
      "    \n",
      "    df =  pd.read_csv('{0}.csv'.format(dset), encoding = \"ISO-8859-1\")\n",
      "    \n",
      "    if verbose:\n",
      "        print('\\n{0:*^80}'.format(' Reading in the {0} dataset '.format(dset)))\n",
      "        print(\"\\nit has {0} rows and {1} columns\".format(*df.shape))\n",
      "        print('\\n{0:*^80}\\n'.format(' It has the following columns '))\n",
      "        print(df.columns)\n",
      "        print('\\n{0:*^80}\\n'.format(' The first 5 rows look like this '))\n",
      "        print(df.head())\n",
      "    \n",
      "    return df\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from modules.helpers import read_in_dataset\n",
    "import inspect\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "print(inspect.getsource(read_in_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************** Reading in the clean_data dataset ***********************\n",
      "\n",
      "it has 855 rows and 20 columns\n",
      "\n",
      "************************* It has the following columns *************************\n",
      "\n",
      "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'airline_sentiment',\n",
      "       'airline_sentiment:confidence', 'negativereason',\n",
      "       'negativereason:confidence', 'airline', 'airline_sentiment_gold',\n",
      "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_id', 'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n",
      "\n",
      "*********************** The first 5 rows look like this ************************\n",
      "\n",
      "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
      "0  681448197    False   finalized                   3      2/25/15 2:26   \n",
      "1  681448213    False   finalized                   3      2/25/15 9:04   \n",
      "2  681448214    False   finalized                   3      2/25/15 9:14   \n",
      "3  681448223    False   finalized                   3      2/25/15 1:57   \n",
      "4  681448228    False   finalized                   3      2/25/15 1:01   \n",
      "\n",
      "  airline_sentiment  airline_sentiment:confidence          negativereason  \\\n",
      "0          positive                         1.000                     NaN   \n",
      "1          negative                         1.000              Bad Flight   \n",
      "2           neutral                         0.615                     NaN   \n",
      "3          negative                         1.000  Customer Service Issue   \n",
      "4          positive                         1.000                     NaN   \n",
      "\n",
      "   negativereason:confidence         airline airline_sentiment_gold  \\\n",
      "0                        NaN  Virgin America                    NaN   \n",
      "1                        1.0  Virgin America                    NaN   \n",
      "2                        0.0  Virgin America                    NaN   \n",
      "3                        1.0  Virgin America                    NaN   \n",
      "4                        NaN  Virgin America                    NaN   \n",
      "\n",
      "              name negativereason_gold  retweet_count  \\\n",
      "0           DT_Les                 NaN              0   \n",
      "1  blackjackpro911                 NaN              0   \n",
      "2  TenantsUpstairs                 NaN              0   \n",
      "3      Cuschoolie1                 NaN              0   \n",
      "4  NorthTxHomeTeam                 NaN              0   \n",
      "\n",
      "                                                text  \\\n",
      "0  @VirginAmerica I love this graphic. http://t.c...   \n",
      "1  @VirginAmerica amazing to me that we can't get...   \n",
      "2  @VirginAmerica LAX to EWR - Middle seat on a r...   \n",
      "3  @VirginAmerica help, left expensive headphones...   \n",
      "4  @VirginAmerica this is great news!  America co...   \n",
      "\n",
      "                    tweet_coord  tweet_created      tweet_id  \\\n",
      "0   [40.74804263, -73.99295302]   2/24/15 8:49  5.702640e+17   \n",
      "1     [42.361016, -71.02000488]   2/24/15 5:05  5.702080e+17   \n",
      "2   [33.94540417, -118.4062472]  2/23/15 23:34  5.701250e+17   \n",
      "3  [33.94209449, -118.40410103]  2/23/15 21:10  5.700880e+17   \n",
      "4     [33.2145038, -96.9321504]  2/23/15 20:24  5.700770e+17   \n",
      "\n",
      "                  tweet_location               user_timezone  \n",
      "0                            NaN                         NaN  \n",
      "1  San Mateo, CA & Las Vegas, NV                         NaN  \n",
      "2                       Brooklyn      Atlantic Time (Canada)  \n",
      "3                  Washington DC                       Quito  \n",
      "4                          Texas  Central Time (US & Canada)  \n",
      "\n",
      "************************ Reading in the cities dataset *************************\n",
      "\n",
      "it has 23278 rows and 19 columns\n",
      "\n",
      "************************* It has the following columns *************************\n",
      "\n",
      "Index(['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude',\n",
      "       'longitude', 'feature class', 'feature code', 'country code', 'cc2',\n",
      "       'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code',\n",
      "       'population', 'elevation', 'dem', 'timezone', 'modification date'],\n",
      "      dtype='object')\n",
      "\n",
      "*********************** The first 5 rows look like this ************************\n",
      "\n",
      "   geonameid              name         asciiname  \\\n",
      "0    3040051      les Escaldes      les Escaldes   \n",
      "1    3041563  Andorra la Vella  Andorra la Vella   \n",
      "2     290594    Umm al Qaywayn    Umm al Qaywayn   \n",
      "3     291074    Ras al-Khaimah    Ras al-Khaimah   \n",
      "4     291696     Khawr FakkÄn      Khawr Fakkan   \n",
      "\n",
      "                                      alternatenames  latitude  longitude  \\\n",
      "0  Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...  42.50729    1.53414   \n",
      "1  ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...  42.50779    1.52109   \n",
      "2  Oumm al Qaiwain,Oumm al QaÃ¯waÃ¯n,Um al Kawain...  25.56473   55.55517   \n",
      "3  Julfa,Khaimah,RKT,Ra's al Khaymah,Ra's al-Chai...  25.78953   55.94320   \n",
      "4  Fakkan,FakkÄn,Khawr Fakkan,Khawr FakkÄn,Khaw...  25.33132   56.34199   \n",
      "\n",
      "  feature class feature code country code  cc2 admin1 code admin2 code  \\\n",
      "0             P         PPLA           AD  NaN          08         NaN   \n",
      "1             P         PPLC           AD  NaN          07         NaN   \n",
      "2             P         PPLA           AE  NaN          07         NaN   \n",
      "3             P         PPLA           AE  NaN          05         NaN   \n",
      "4             P          PPL           AE  NaN          06         NaN   \n",
      "\n",
      "  admin3 code admin4 code  population  elevation   dem        timezone  \\\n",
      "0         NaN         NaN       15853        NaN  1033  Europe/Andorra   \n",
      "1         NaN         NaN       20430        NaN  1037  Europe/Andorra   \n",
      "2         NaN         NaN       44411        NaN     2      Asia/Dubai   \n",
      "3         NaN         NaN      115949        NaN     2      Asia/Dubai   \n",
      "4         NaN         NaN       33575        NaN    20      Asia/Dubai   \n",
      "\n",
      "  modification date  \n",
      "0        2008-10-15  \n",
      "1        2010-05-30  \n",
      "2        2014-10-07  \n",
      "3        2015-12-05  \n",
      "4        2013-10-25  \n"
     ]
    }
   ],
   "source": [
    "cleaned_data_df = read_in_dataset('clean_data', verbose = True)\n",
    "cities_df = read_in_dataset('cities', verbose= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the cities_df  in the right format for training\n",
    "\n",
    "- The \"X\" variables will be the closest city to the \"tweet_coord\" using Euclidean distance.\n",
    " - use the `cities.csv` file to find the closest city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>alternatenames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>feature class</th>\n",
       "      <th>feature code</th>\n",
       "      <th>country code</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1 code</th>\n",
       "      <th>admin2 code</th>\n",
       "      <th>admin3 code</th>\n",
       "      <th>admin4 code</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>dem</th>\n",
       "      <th>timezone</th>\n",
       "      <th>modification date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3040051</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1033</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3041563</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2010-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290594</td>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>Oumm al Qaiwain,Oumm al QaÃ¯waÃ¯n,Um al Kawain...</td>\n",
       "      <td>25.56473</td>\n",
       "      <td>55.55517</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2014-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291074</td>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>Julfa,Khaimah,RKT,Ra's al Khaymah,Ra's al-Chai...</td>\n",
       "      <td>25.78953</td>\n",
       "      <td>55.94320</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2015-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291696</td>\n",
       "      <td>Khawr FakkÄn</td>\n",
       "      <td>Khawr Fakkan</td>\n",
       "      <td>Fakkan,FakkÄn,Khawr Fakkan,Khawr FakkÄn,Khaw...</td>\n",
       "      <td>25.33132</td>\n",
       "      <td>56.34199</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2013-10-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid              name         asciiname  \\\n",
       "0    3040051      les Escaldes      les Escaldes   \n",
       "1    3041563  Andorra la Vella  Andorra la Vella   \n",
       "2     290594    Umm al Qaywayn    Umm al Qaywayn   \n",
       "3     291074    Ras al-Khaimah    Ras al-Khaimah   \n",
       "4     291696     Khawr FakkÄn      Khawr Fakkan   \n",
       "\n",
       "                                      alternatenames  latitude  longitude  \\\n",
       "0  Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...  42.50729    1.53414   \n",
       "1  ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...  42.50779    1.52109   \n",
       "2  Oumm al Qaiwain,Oumm al QaÃ¯waÃ¯n,Um al Kawain...  25.56473   55.55517   \n",
       "3  Julfa,Khaimah,RKT,Ra's al Khaymah,Ra's al-Chai...  25.78953   55.94320   \n",
       "4  Fakkan,FakkÄn,Khawr Fakkan,Khawr FakkÄn,Khaw...  25.33132   56.34199   \n",
       "\n",
       "  feature class feature code country code  cc2 admin1 code admin2 code  \\\n",
       "0             P         PPLA           AD  NaN          08         NaN   \n",
       "1             P         PPLC           AD  NaN          07         NaN   \n",
       "2             P         PPLA           AE  NaN          07         NaN   \n",
       "3             P         PPLA           AE  NaN          05         NaN   \n",
       "4             P          PPL           AE  NaN          06         NaN   \n",
       "\n",
       "  admin3 code admin4 code  population  elevation   dem        timezone  \\\n",
       "0         NaN         NaN       15853        NaN  1033  Europe/Andorra   \n",
       "1         NaN         NaN       20430        NaN  1037  Europe/Andorra   \n",
       "2         NaN         NaN       44411        NaN     2      Asia/Dubai   \n",
       "3         NaN         NaN      115949        NaN     2      Asia/Dubai   \n",
       "4         NaN         NaN       33575        NaN    20      Asia/Dubai   \n",
       "\n",
       "  modification date  \n",
       "0        2008-10-15  \n",
       "1        2010-05-30  \n",
       "2        2014-10-07  \n",
       "3        2015-12-05  \n",
       "4        2013-10-25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.latitude.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.longitude.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geonameid                0\n",
       "dem                      0\n",
       "population               0\n",
       "timezone                 0\n",
       "feature code             0\n",
       "feature class            0\n",
       "modification date        0\n",
       "latitude                 0\n",
       "asciiname                0\n",
       "name                     0\n",
       "longitude                0\n",
       "admin1 code              7\n",
       "country code            13\n",
       "alternatenames        1997\n",
       "admin2 code           7211\n",
       "admin3 code          16252\n",
       "elevation            19592\n",
       "admin4 code          21065\n",
       "cc2                  23036\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.isnull().sum().sort_values(ascending=True)  # no missing values in the relevant columns\n",
    "# no missing values in the relevant columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.latitude.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [40.74804263, -73.99295302]\n",
       "1       [42.361016, -71.02000488]\n",
       "2     [33.94540417, -118.4062472]\n",
       "3    [33.94209449, -118.40410103]\n",
       "4       [33.2145038, -96.9321504]\n",
       "Name: tweet_coord, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_df.tweet_coord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find the the closest city to the \"tweet_coord\" using Euclidean distance\n",
    "\n",
    "- and map them with the cleaned_data_df, merge the name column from the cities dataframe with cleaned_data_df\n",
    "    - find the distance for each of cleaned_data_df with cities_coordinates and sort them based on the euclidian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " from ast import literal_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first the find the closest city for the first tweet coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dist(lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "     the function that calculates the euclidian distance of the lat and long of two points\n",
    "    \"\"\"\n",
    "    return np.sqrt((lat1-lat2)**2+(long1-long2)**2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first the find the closest city for the first tweet coordinate\n",
    "def find_closest_city(lat, long):\n",
    "    \n",
    "    distances = cities_df.apply(lambda row: dist(lat, long, row['latitude'], row['longitude']), axis=1)\n",
    "    \n",
    "    return cities_df.loc[distances.idxmin(), 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 40.74804263\n",
    "long = -73.99295302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York City'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_city(lat, long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find the corresponding closed city for each tweet in the cleaned_data_df\n",
    "- the function literal_eval removes the string quotes and coonvert the [lat, long] in float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "closest_cities = cleaned_data_df.apply(\n",
    "    lambda row: find_closest_city(literal_eval(row['tweet_coord'])[0], literal_eval(row['tweet_coord'])[1]), \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            New York City\n",
       "1                  Chelsea\n",
       "2               El Segundo\n",
       "3               El Segundo\n",
       "4                   Frisco\n",
       "5              Culver City\n",
       "6              Aliso Viejo\n",
       "7      Springfield Gardens\n",
       "8                 Paradise\n",
       "9            San Francisco\n",
       "10             Dania Beach\n",
       "11              El Segundo\n",
       "12                 Calgary\n",
       "13     Springfield Gardens\n",
       "14              El Segundo\n",
       "15        Washington, D.C.\n",
       "16                  Dallas\n",
       "17                  Dallas\n",
       "18             Dania Beach\n",
       "19                  Dallas\n",
       "20               Gladstone\n",
       "21           San Francisco\n",
       "22              El Segundo\n",
       "23           Port Richmond\n",
       "24              Ronkonkoma\n",
       "25                Westford\n",
       "26           San Francisco\n",
       "27         Summerlin South\n",
       "28     Venustiano Carranza\n",
       "29                Brighton\n",
       "              ...         \n",
       "825              Charlotte\n",
       "826           Santa Monica\n",
       "827    Springfield Gardens\n",
       "828    Springfield Gardens\n",
       "829              Charlotte\n",
       "830                Coppell\n",
       "831       Washington, D.C.\n",
       "832           Mount Vernon\n",
       "833    Springfield Gardens\n",
       "834            Morrisville\n",
       "835           Howard Beach\n",
       "836                Garland\n",
       "837                Flagami\n",
       "838           Angeles City\n",
       "839       Washington, D.C.\n",
       "840                 Tacoma\n",
       "841    Springfield Gardens\n",
       "842                Garland\n",
       "843              Elizabeth\n",
       "844                Augusta\n",
       "845                 Harlem\n",
       "846               Montrose\n",
       "847               Montrose\n",
       "848             East Point\n",
       "849              Grapevine\n",
       "850             El Segundo\n",
       "851             Rio Rancho\n",
       "852           Mount Vernon\n",
       "853              Grapevine\n",
       "854    Springfield Gardens\n",
       "Length: 855, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(closest_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column at the cleaned _data_df with the corresponding closest cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>...</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>closest_cities</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448197</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 2:26</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.c...</td>\n",
       "      <td>[40.74804263, -73.99295302]</td>\n",
       "      <td>2/24/15 8:49</td>\n",
       "      <td>5.702640e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681448213</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 9:04</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica amazing to me that we can't get...</td>\n",
       "      <td>[42.361016, -71.02000488]</td>\n",
       "      <td>2/24/15 5:05</td>\n",
       "      <td>5.702080e+17</td>\n",
       "      <td>San Mateo, CA &amp; Las Vegas, NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681448214</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 9:14</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica LAX to EWR - Middle seat on a r...</td>\n",
       "      <td>[33.94540417, -118.4062472]</td>\n",
       "      <td>2/23/15 23:34</td>\n",
       "      <td>5.701250e+17</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681448223</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:57</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica help, left expensive headphones...</td>\n",
       "      <td>[33.94209449, -118.40410103]</td>\n",
       "      <td>2/23/15 21:10</td>\n",
       "      <td>5.700880e+17</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>Quito</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681448228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:01</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica this is great news!  America co...</td>\n",
       "      <td>[33.2145038, -96.9321504]</td>\n",
       "      <td>2/23/15 20:24</td>\n",
       "      <td>5.700770e+17</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>Frisco</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448197    False   finalized                   3      2/25/15 2:26   \n",
       "1  681448213    False   finalized                   3      2/25/15 9:04   \n",
       "2  681448214    False   finalized                   3      2/25/15 9:14   \n",
       "3  681448223    False   finalized                   3      2/25/15 1:57   \n",
       "4  681448228    False   finalized                   3      2/25/15 1:01   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence          negativereason  \\\n",
       "0          positive                         1.000                     NaN   \n",
       "1          negative                         1.000              Bad Flight   \n",
       "2           neutral                         0.615                     NaN   \n",
       "3          negative                         1.000  Customer Service Issue   \n",
       "4          positive                         1.000                     NaN   \n",
       "\n",
       "   negativereason:confidence         airline  ... negativereason_gold  \\\n",
       "0                        NaN  Virgin America  ...                 NaN   \n",
       "1                        1.0  Virgin America  ...                 NaN   \n",
       "2                        0.0  Virgin America  ...                 NaN   \n",
       "3                        1.0  Virgin America  ...                 NaN   \n",
       "4                        NaN  Virgin America  ...                 NaN   \n",
       "\n",
       "  retweet_count                                               text  \\\n",
       "0             0  @VirginAmerica I love this graphic. http://t.c...   \n",
       "1             0  @VirginAmerica amazing to me that we can't get...   \n",
       "2             0  @VirginAmerica LAX to EWR - Middle seat on a r...   \n",
       "3             0  @VirginAmerica help, left expensive headphones...   \n",
       "4             0  @VirginAmerica this is great news!  America co...   \n",
       "\n",
       "                    tweet_coord  tweet_created      tweet_id  \\\n",
       "0   [40.74804263, -73.99295302]   2/24/15 8:49  5.702640e+17   \n",
       "1     [42.361016, -71.02000488]   2/24/15 5:05  5.702080e+17   \n",
       "2   [33.94540417, -118.4062472]  2/23/15 23:34  5.701250e+17   \n",
       "3  [33.94209449, -118.40410103]  2/23/15 21:10  5.700880e+17   \n",
       "4     [33.2145038, -96.9321504]  2/23/15 20:24  5.700770e+17   \n",
       "\n",
       "                  tweet_location               user_timezone closest_cities  \\\n",
       "0                            NaN                         NaN  New York City   \n",
       "1  San Mateo, CA & Las Vegas, NV                         NaN        Chelsea   \n",
       "2                       Brooklyn      Atlantic Time (Canada)     El Segundo   \n",
       "3                  Washington DC                       Quito     El Segundo   \n",
       "4                          Texas  Central Time (US & Canada)         Frisco   \n",
       "\n",
       "  sentiment  \n",
       "0       2.0  \n",
       "1       0.0  \n",
       "2       1.0  \n",
       "3       0.0  \n",
       "4       2.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_df['closest_cities'] = closest_cities\n",
    "cleaned_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column that maps (0, 1, 2 for negative, neutral and positive respectively) of ariline_sentiment\n",
    "cleaned_data_df.loc[cleaned_data_df['airline_sentiment']=='negative', \n",
    "             'sentiment'] = 0\n",
    "cleaned_data_df.loc[cleaned_data_df['airline_sentiment']=='neutral', \n",
    "             'sentiment'] = 1\n",
    "cleaned_data_df.loc[cleaned_data_df['airline_sentiment']=='positive', \n",
    "             'sentiment'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    0.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    2.0\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = cleaned_data_df.sentiment\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the prepared data for training to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_df.to_csv('training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = cleaned_data_df.closest_cities\n",
    "y = cleaned_data_df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 291)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelBinarizer()\n",
    "X_lb = encoder.fit_transform(X)\n",
    "X_lb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to file\n",
    "Output file should have columns corresponding to the training data:\n",
    "        - y = airline_sentiment (coded as 0=negative, 1=neutral, 2=positive)\n",
    "        - X = a one-hot coded column for each city in \"cities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe: that contains X_lb and Y\n",
    "x = X_lb.tolist()\n",
    "y = y.to_list()\n",
    "\n",
    "features_df = pd.DataFrame(\n",
    "    {'X': x,\n",
    "     'y': y,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
